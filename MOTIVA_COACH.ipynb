{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "285767f3-70ab-426c-8fd6-5b4bd32ba17e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* Running on public URL: https://ee939fc6489dc6384f.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://ee939fc6489dc6384f.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import gradio as gr\n",
    "import json\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "\n",
    "# Load .env\n",
    "load_dotenv()\n",
    "\n",
    "# Setup models and tools\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "search_tool = DuckDuckGoSearchRun()\n",
    "llm_with_tools = llm.bind_tools([search_tool])\n",
    "\n",
    "# Define prompt structure\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"You are a knowledgeable and friendly running coach. \n",
    "Step 1: Introduce yourself to the user as Motiva, an AI running coach. Tell them that you are here to help them with their running goals and teach them more about running. You should always wait for a response from the user after every question before moving on. Work on understanding their goals. Ask one question at a time and explain that you are asking these questions to personalize the chat. Do not start explaining right away before gathering their information.\n",
    "\n",
    "Step 2: Look up information that would help you answer their questions and complete their goals. They might offer a running summary of their progress, and to that assess whether their goals are possible. Think step by step and make a plan based on the goal. Once you know about the runner and their goals, advise the runner in an informed, helpful way. Break down the advice and tailor your response and questions to the runner. This will change as the conversation progresses. Once you have enough information, tell the runner you are happy to help them with other things they need help with.\n",
    "\n",
    "Step 3: Close the conversation. When the runner has no more questions or doesn't need any more help, please insert a motivational quote and tell them you are here to help in the future.\"\"\"),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"human\", \"{input}\"),\n",
    "])\n",
    "chain = prompt | llm_with_tools | StrOutputParser()\n",
    "\n",
    "# Simulated user profile (persistent between messages)\n",
    "user_profile = {\n",
    "    \"goal\": None,\n",
    "    \"runner_type\": None,\n",
    "    \"shoe_mileage\": None,\n",
    "    \"injuries\": []\n",
    "}\n",
    "\n",
    "# Store uploaded running data\n",
    "running_data_df = None\n",
    "\n",
    "# Gradio-compatible chat function\n",
    "def chat_fn(message, history):\n",
    "    global running_data_df\n",
    "\n",
    "    # Preprocess input to simulate memory update\n",
    "    if \"goal\" in message.lower() and not user_profile[\"goal\"]:\n",
    "        user_profile[\"goal\"] = message\n",
    "    if \"beginner\" in message.lower() or \"casual\" in message.lower() or \"expert\" in message.lower():\n",
    "        user_profile[\"runner_type\"] = message\n",
    "    if \"miles\" in message.lower() and any(char.isdigit() for char in message):\n",
    "        user_profile[\"shoe_mileage\"] = int([int(s) for s in message.split() if s.isdigit()][0])\n",
    "    if \"pain\" in message.lower() or \"injury\" in message.lower():\n",
    "        user_profile[\"injuries\"].append(message)\n",
    "\n",
    "    print(f\"USER PROFILE: {user_profile}\")  # Debug print\n",
    "\n",
    "    # Inject summary into prompt context if running data is available\n",
    "    if running_data_df is not None:\n",
    "        summary = generate_summary(running_data_df)\n",
    "        message = f\"{summary}\\n\\nUser says: {message}\"\n",
    "\n",
    "    response = chain.invoke({\"input\": message, \"chat_history\": history})\n",
    "    return response\n",
    "\n",
    "# File upload function\n",
    "def handle_file(file):\n",
    "    global running_data_df\n",
    "    running_data_df = pd.read_csv(file.name)\n",
    "    print(running_data_df.columns)  # Debug print to inspect column names\n",
    "    return generate_summary(running_data_df)\n",
    "\n",
    "# Generate quick summary\n",
    "def generate_summary(df):\n",
    "    try:\n",
    "        df = df.copy()\n",
    "        total_distance = df['distance'].sum() / 1000  # Convert to km\n",
    "        avg_distance = df['distance'].mean() / 1000  # Convert to km\n",
    "\n",
    "        # Filter valid pace entries (distance > 0)\n",
    "        valid_df = df[(df['distance'] > 0) & (df['moving_time'] > 0)]\n",
    "\n",
    "        if not valid_df.empty:\n",
    "            valid_df['pace_min_per_km'] = (valid_df['moving_time'] / valid_df['distance']) * (1000 / 60)\n",
    "            avg_pace = valid_df['pace_min_per_km'].mean()\n",
    "        else:\n",
    "            avg_pace = \"N/A\"\n",
    "\n",
    "        total_runs = len(df)\n",
    "\n",
    "        if isinstance(avg_pace, float) and not pd.isna(avg_pace):\n",
    "            pace_str = f\"{avg_pace:.2f} min/km\"\n",
    "        else:\n",
    "            pace_str = str(avg_pace)\n",
    "\n",
    "        summary = f\"\"\"\\nüìä **Running Data Summary**:\n",
    "- Total runs: {total_runs}\n",
    "- Total distance: {total_distance:.2f} km\n",
    "- Average distance: {avg_distance:.2f} km/run\n",
    "- Average pace: {pace_str}\"\"\"\n",
    "\n",
    "        return summary\n",
    "    except Exception as e:\n",
    "        return f\"Error reading file: {e}\"\n",
    "\n",
    "# Launch Gradio interface\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"# üèÉ Running Coach Chatbox\")\n",
    "    file_input = gr.File(label=\"Upload CSV Running Data\", file_types=[\".csv\"])\n",
    "    file_output = gr.Textbox(label=\"Data Summary\", lines=6)\n",
    "\n",
    "    file_input.change(fn=handle_file, inputs=file_input, outputs=file_output)\n",
    "\n",
    "    gr.ChatInterface(fn=chat_fn, type=\"messages\")\n",
    "\n",
    "demo.launch(share=True)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3-12 (COMM4190)",
   "language": "python",
   "name": "python3-12_comm4190"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
